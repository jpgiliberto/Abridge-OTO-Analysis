---
title: "Abridge AI Scribe in OTO"
author: "JP Giliberto and Jen Ren"
format: html
---

## Wrangle
### Load Packages
```{r}
#|code-fold: true
#|warning: false
#|warning: false

#loading standard packages for data wrangle and visualization. JPG just commented out packages I don't think we will use. 
library (tidyverse)
library(readr)
library (lubridate)
library(readxl)
library(forcats)
library(scales)
library(ggthemes)
library(ggrepel)
library(janitor)
library(gt)
#library(ggridges)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(fuzzyjoin)
#library(ggsignif)

```

### Load DeID data

```{r}
#|code-fold: true
#|warning: false
#|warning: false

# Sessions are number of abridge activations
SessionsRaw <- read_csv("Raw Data DeID/Abridge Sessions 09 25 to 11 25.csv") |> 
  select(2:4)

#signal data raw with dates
SignalRaw1 <- read_csv("Raw Data DeID/Signal Data 12 22 to 11 25.csv") |> 
  select(StartDate = `Reporting Period Start Date`, EndDate = `Reporting Period End Date`, 4:8) |> 
  mutate(GroupData = case_when(StudyID == "ID928" & StartDate >"2025-02-01" ~ "AIScribe",
                               StudyID == "ID928" & StartDate <"2025-01-01" ~ "Control",
                               StudyID == "ID928"  ~ "Transition",
                               StartDate > "2025-9-01"~ "AIScribe",
                               StartDate < "2025-08-15" ~"Control",
                               T ~"Transition")
                )

#eliminate months where the provider did not see more than a threshold (at least 20). 25 of 778 (3.2%) provider months eliminated
KeyApptsPerMo <- SignalRaw1 |> 
  filter(Metric == "Appointments per Day") |> 
  select(StudyID, StartDate,Numerator) |> 
  mutate(ThresholdAppt = Numerator >19) |>  
  #count(ThresholdAppt) |> 
  select(-Numerator)

SignalRaw <- SignalRaw1 |> 
  left_join(KeyApptsPerMo) |> 
  filter(ThresholdAppt) |> 
  select(-ThresholdAppt)

SurveyRaw <- read_csv("Raw Data DeID/Survey - Baseline.csv") |> 
  select(2:57)

VisitsRaw <- read_csv("Raw Data DeID/visits data 12 1 2022 to 12 18.csv") |> 
  select(VisitType = `Visit Type`, Date = `Visit Date`, LOS = `Level of Service`, StudyID) |> 
  filter(LOS !="ERROR") |> 
  filter(!str_detect(VisitType, "SUPPORT")) |> 
  mutate(VisitCat = case_when(str_detect(VisitType,"NEW")~ "NEW",
                             str_detect(VisitType,"TELE")~ "TELEMED",
                             str_detect(LOS, "9924")~ "TELEMED",
                             str_detect(LOS, "99241")~ "TELEMED",
                             str_detect(LOS, "9921")~ "RETURN",
                             str_detect(LOS, "99024")~ "OTHER",
                             str_detect(LOS,  "PROC")~ "OTHER",
                             str_detect(VisitType,  "PROCEDURE")~ "OTHER",
                             str_detect(LOS,  "NOCH")~ "OTHER",
                             str_detect(LOS, "99203")~ "NEW",
                             str_detect(LOS, "99204")~ "NEW",
                             str_detect(LOS, "99205")~ "NEW",
                             str_detect(VisitType, "BOTOX")~"OTHER",
                             T~"RETURN")) |> #what was left was 99202 in a return slot
  group_by(StudyID, Date,VisitCat) |> 
  summarise(n= n()) |> 
  pivot_wider(names_from = VisitCat, values_from = n)

VisitsRaw$Date <- ymd( VisitsRaw$Date, tz = "UTC")

#need to validate raw visit data looks okay? when I look at mine ID928

```

### Create or Load Keys
```{r}
KeyIDRole <- read_csv("Participant Key ID.csv") |> 
  select(2:3)

KeyPercentAmbient <- SignalRaw |> 
  filter(str_detect(Metric, "mbient")) |> 
  select(StudyID, StartDate,PercentAmbient = Value)

#High vs Low Users. we can discuss best way to do that. median 106
KeyUserHigh <- SessionsRaw |> 
  group_by(StudyID) |> 
  summarise(n = sum(`Abridge Sessions`, na.rm = T)) |> 
  #12/20 median number of total usage was 105 will need to update
  mutate(HighUser = n>105) #|> 
  #select(-n)
  
KeyDenominator<- SignalRaw |> 
  select(StudyID,StartDate, EndDate,Metric, Numerator, Denominator) |>
  mutate(DenomUnits = case_when(str_detect(Metric, "Time in Notes per Appointment") ~ "per Appointment",
                                 str_detect(Metric, "Time in System per Day") ~ "per Day with a Login",
                                 str_detect(Metric, "Time On Unscheduled Days") ~ "per Unscheduled Day",
                                str_detect(Metric, "Appointments per Day") ~ "per Scheduled Day",
                                 T ~ NA)) |> 
  filter(!is.na(DenomUnits)) |> 
  group_by(StudyID,StartDate, EndDate, DenomUnits) |> 
  summarise(denom_max = max(Denominator, na.rm = T)) |> 
  pivot_wider(names_from = DenomUnits,values_from = denom_max)


BaselineMeans <- SignalRaw |> 
  filter(GroupData=="Control") |> 
  group_by(Metric, StudyID) |> 
  summarize(Count = n(),
            BaselineMean = mean(Value, na.rm = T))

BaselineNotesPerAppt <- BaselineMeans |> 
  filter(Metric =="Time in Notes per Appointment")
 
```

## Data Exploration Visualization
### Pajama Time Figure
```{r}
Pajama <- SignalRaw |> 
  filter(Metric == "Pajama Time") |> 
  left_join(KeyUserHigh)

ggplot(Pajama, aes(x = StartDate, y = Value))+
  geom_point(aes(color=GroupData), size = 1.5)+
  geom_line(color = "grey60")+
  facet_grid(StudyID~HighUser, scales = "free_y",)+
  ylab("PJ Time per Scheduled Day")+
  theme_bw()

#ggsave ("PJ Time All Users.jpg", device = "jpeg",path = "C://Users//jpgil//OneDrive//Research - Primary//Epic//Abridge OTO//Abridge OTO Analysis//Figures", dpi = "retina", units = "in", height = 12 ,width = 8  )

```

### Pajamtime table

```{r}
PajamaDescr <- Pajama |> 
  group_by(StudyID,HighUser, GroupData) |> 
  summarise(Mean = mean (Value)) |>
  pivot_wider(names_from = "GroupData", values_from = Mean) |> 
  select(-Transition) |>
  mutate(Difference = Control - AIScribe ) |> 
  arrange(desc(Difference)) |> 
  gt()
  
PajamaDescr  
```

### Time in Notes per Appointment
```{r}
TimeInNotes <- SignalRaw |>
  filter(Metric == "Time in Notes per Appointment") |>
  filter(GroupData =="AIScribe") |> 
  left_join(KeyUserHigh) |> 
  left_join(BaselineNotesPerAppt, join_by (StudyID, Metric)) |> 
  #Change in Notes is the observed value subtracted from the current value. We will get sone for each month. and then average them. 
   mutate(ChangeInNotesPerApp =  Value - BaselineMean,
          EstimatedHrsSaved = Numerator/60 - BaselineMean*Denominator/60,
          PercentNotesSaved = ChangeInNotesPerApp/BaselineMean ) |>
  left_join(KeyPercentAmbient, join_by(StudyID,StartDate))


AverageTimeInNotesUser <- TimeInNotes |> 
  group_by(StudyID, HighUser) |> 
  summarise(MeanChangeInNotesApp = mean(ChangeInNotesPerApp),
            MeanEstimatedHrsSave = mean(EstimatedHrsSaved),
            MeanPercenterAmbient = mean(PercentNotesSaved))

AverageTimeInNotesByHighUser <- AverageTimeInNotesUser |> 
  group_by(HighUser) |> 
 summarise(MeanChangeInNotesApp = mean(MeanChangeInNotesApp),
            MeanEstimatedHrsSave = mean(MeanEstimatedHrsSave),
            MeanPercenterAmbient = mean(MeanPercenterAmbient))
  ggplot(TimeInNotes, aes(x = StartDate, y = Value))+
  geom_point(aes(color=GroupData), size = 1.5)+
  geom_line(color = "grey60")+
  facet_grid(StudyID~HighUser, scales = "free_y",)+
  ylab("PJ Time per Scheduled Day")+
  theme_bw()

#ggsave ("Notes All Users.jpg", device = "jpeg",path = "C://Users//jpgil//OneDrive//Research - Primary//Epic//Abridge OTO//Abridge OTO Analysis//Figures", dpi = "retina", units = "in", height = 12 ,width = 8  )


```

### Atempt at Linear Mixed Effect Model for Notes
Seems to be possile for Large data set like control, but does not seem to make sense for post
```{r}
TimeInNotesAll <- SignalRaw |>
  filter(Metric == "Time in Notes per Appointment") |> 
  select(-Metric)

VisitsPerMo1 <- VisitsRaw |> 
  mutate(StartDate = case_when( Date <= "2022-12-31"~"2022-11-27",
                                Date <= "2023-01-28"~"2023-01-01",
                                Date <= "2023-02-25"~"2023-01-29",
                                Date <= "2023-03-25"~"2023-02-26",
                                Date <= "2023-04-29"~"2023-03-26",
                                Date <= "2023-05-27"~"2023-04-30",
                                Date <= "2023-06-24"~"2023-05-28",
                                Date <= "2023-07-29"~"2023-06-25",
                                Date <= "2023-08-26"~"2023-07-30",
                                Date <= "2023-09-30"~"2023-08-27",
                                Date <= "2023-10-28"~"2023-10-01",
                                Date <= "2023-11-25"~"2023-10-29",
                                Date <= "2023-12-30"~"2023-11-26",
                                Date <= "2024-01-27"~"2023-12-31",
                                Date <= "2024-02-24"~"2024-01-28",
                                Date <= "2024-03-30"~"2024-02-25",
                                Date <= "2024-04-27"~"2024-03-31",
                                Date <= "2024-05-25"~"2024-04-28",
                                Date <= "2024-06-29"~"2024-05-26",
                                Date <= "2024-07-27"~"2024-06-30",
                                Date <= "2024-08-31"~"2024-07-28",
                                Date <= "2024-09-28"~"2024-09-01",
                                Date <= "2024-10-26"~"2024-09-29",
                                Date <= "2024-11-30"~"2024-10-27",
                                Date <= "2024-12-28"~"2024-12-01",
                                Date <= "2025-01-25"~"2024-12-29",
                                Date <= "2025-02-22"~"2025-01-26",
                                Date <= "2025-03-29"~"2025-02-23",
                                Date <= "2025-04-26"~"2025-03-30",
                                Date <= "2025-05-31"~"2025-04-27",
                                Date <= "2025-06-28"~"2025-06-01",
                                Date <= "2025-07-26"~"2025-06-29",
                                Date <= "2025-08-30"~"2025-07-27",
                                Date <= "2025-09-27"~"2025-08-31",
                                Date <= "2025-10-25"~"2025-09-28",
                                Date <= "2025-11-29"~"2025-10-26",
                                T~NA))



VisitsPerMo <-  VisitsPerMo1 |> 
  group_by(StudyID,StartDate) |> 
  summarise(New = sum(NEW, na.rm =T),
            #Return did not differ from telemed so we combine them
            Return = sum(RETURN, na.rm =T),
            Other = sum(OTHER, na.rm = T),
            Telemed = sum(TELEMED, na.rm = T),
            Total = sum(NEW, RETURN, OTHER, TELEMED, na.rm = T)) |> 
  filter(Total>19) |> 
  filter(!is.na(StartDate))

VisitsPerMo$StartDate <- ymd(VisitsPerMo$StartDate, tz = "UTC")


TimeInNotesLM <- TimeInNotesAll |> 
  left_join(VisitsPerMo,join_by(StudyID, StartDate)) |> 
  left_join(KeyUserHigh)

# numbers are off for totals from visits and denominator of total sum of visits. We will need to look at that and take whatever number is more reliable. 


NotesData4LMEM = TimeInNotesLM |> 
  filter(GroupData == "Control") |> 
  filter(HighUser)

NotesData4LMEM$StudyID <- as_factor(NotesData4LMEM$StudyID)

NotesControlLMEM <- lmer(formula = Numerator ~ (New) + (Return) + (Other) + (Telemed) + (1|StudyID), data=NotesData4LMEM)


summary(NotesControlLMEM)				


```


### Graph of Percent Saves and Percent ambient
```{r}
ggplot(TimeInNotes)+
  geom_boxplot( aes(x = HighUser, y = EstimatedHrsSaved))+
  coord_flip()
 

```





